{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import awkward0\n",
    "import uproot3_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='[%(asctime)s] %(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rd804/discriminator-metric\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rd804/discriminator-metric'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform(data, label, jet_size=0.8):\n",
    "    from collections import OrderedDict\n",
    "    v = OrderedDict()\n",
    "\n",
    "    _e = data[...,0]\n",
    "    _px = data[...,1]\n",
    "    _py = data[...,2]\n",
    "    _pz = data[...,3]\n",
    "    \n",
    "    mask = _e>0\n",
    "    n_particles = np.sum(mask, axis=1)\n",
    "\n",
    "   # print('num particles: ',n_particles[0:20])\n",
    "\n",
    "    px = awkward0.JaggedArray.fromcounts(n_particles, _px[mask])\n",
    "    py = awkward0.JaggedArray.fromcounts(n_particles, _py[mask])\n",
    "    pz = awkward0.JaggedArray.fromcounts(n_particles, _pz[mask])\n",
    "    energy = awkward0.JaggedArray.fromcounts(n_particles, _e[mask])\n",
    "\n",
    "    p4 = uproot3_methods.TLorentzVectorArray.from_cartesian(px, py, pz, energy)\n",
    "\n",
    "    #print(p4)\n",
    "    pt = p4.pt\n",
    "\n",
    "    jet_p4 = p4.sum()\n",
    "\n",
    "    # outputs\n",
    "    _label = label\n",
    "    v['label'] = np.stack((_label, 1-_label), axis=-1)\n",
    "    #v['train_val_test'] = df['ttv'].values\n",
    "    \n",
    "    v['jet_pt'] = jet_p4.pt\n",
    "    v['jet_eta'] = jet_p4.eta\n",
    "    v['jet_phi'] = jet_p4.phi\n",
    "    v['jet_mass'] = jet_p4.mass\n",
    "    v['n_parts'] = n_particles\n",
    "\n",
    "    v['part_px'] = px\n",
    "    v['part_py'] = py\n",
    "    v['part_pz'] = pz\n",
    "    v['part_energy'] = energy\n",
    "\n",
    "    v['part_pt_log'] = np.log(pt)\n",
    "    v['part_ptrel'] = pt/v['jet_pt']\n",
    "    v['part_logptrel'] = np.log(v['part_ptrel'])\n",
    "\n",
    "    v['part_e_log'] = np.log(energy)\n",
    "    v['part_erel'] = energy/jet_p4.energy\n",
    "    v['part_logerel'] = np.log(v['part_erel'])\n",
    "\n",
    "    v['part_raw_etarel'] = (p4.eta - v['jet_eta'])\n",
    "    _jet_etasign = np.sign(v['jet_eta'])\n",
    "    _jet_etasign[_jet_etasign==0] = 1\n",
    "    v['part_etarel'] = v['part_raw_etarel'] * _jet_etasign\n",
    "\n",
    "    v['part_phirel'] = p4.delta_phi(jet_p4)\n",
    "    v['part_deltaR'] = np.hypot(v['part_etarel'], v['part_phirel'])\n",
    "\n",
    "    def _make_image(var_img, rec, n_pixels = 64, img_ranges = [[-0.8, 0.8], [-0.8, 0.8]]):\n",
    "        wgt = rec[var_img]\n",
    "        x = rec['part_etarel']\n",
    "        y = rec['part_phirel']\n",
    "        img = np.zeros(shape=(len(wgt), n_pixels, n_pixels))\n",
    "        for i in range(len(wgt)):\n",
    "            hist2d, xedges, yedges = np.histogram2d(x[i], y[i], bins=[n_pixels, n_pixels], range=img_ranges, weights=wgt[i])\n",
    "            img[i] = hist2d\n",
    "        return img\n",
    "\n",
    "#     v['img'] = _make_image('part_ptrel', v)\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data,label, destdir, basename, step=None, limit=None):\n",
    "\n",
    "    if not os.path.exists(destdir):\n",
    "        os.makedirs(destdir)\n",
    "    output = os.path.join(destdir, '%s.awkd'%(basename))\n",
    "    logging.info(output)\n",
    "\n",
    "    if os.path.exists(output):\n",
    "        logging.warning('... file already exist: continue ...')\n",
    "        return\n",
    "    v=_transform(data,label)\n",
    "    awkward0.save(output, v, mode='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcDir = 'data'\n",
    "destDir = 'data/converted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-17 18:55:41,912] INFO: data/converted/train_shifted_file.awkd\n",
      "[2023-04-17 18:55:43,781] INFO: data/converted/valid_shifted_file.awkd\n",
      "[2023-04-17 18:55:44,752] INFO: data/converted/train_eta_smeared_file.awkd\n",
      "[2023-04-17 18:55:47,906] INFO: data/converted/valid_eta_smeared_file.awkd\n",
      "[2023-04-17 18:55:49,878] INFO: data/converted/train_smeared_file.awkd\n",
      "[2023-04-17 18:55:52,300] INFO: data/converted/valid_smeared_file.awkd\n",
      "[2023-04-17 18:55:55,852] INFO: data/converted/train_pt_shifted_file.awkd\n",
      "[2023-04-17 18:55:59,936] INFO: data/converted/valid_pt_shifted_file.awkd\n",
      "[2023-04-17 18:56:04,070] INFO: data/converted/train_pt_smeared_file.awkd\n",
      "[2023-04-17 18:56:10,066] INFO: data/converted/valid_pt_smeared_file.awkd\n",
      "[2023-04-17 18:56:18,112] INFO: data/converted/train_all_smeared_file.awkd\n",
      "[2023-04-17 18:56:21,839] INFO: data/converted/valid_all_smeared_file.awkd\n"
     ]
    }
   ],
   "source": [
    "# convert training file\n",
    "test_jets = ['shifted','eta_smeared','smeared','pt_shifted','pt_smeared','all_smeared']\n",
    "split = ['train', 'valid']\n",
    "\n",
    "for test_jet in test_jets:\n",
    "    for s in split:\n",
    "        particle_data = pd.read_hdf('data/jetnet30_data.h5', f'particle_data_{test_jet}_{s}').values.reshape(-1,30,4)\n",
    "        labels = pd.read_hdf('data/jetnet30_data.h5', f'labels__{test_jet}_{s}').values\n",
    "        convert(data=particle_data,label=labels, destdir=destDir, basename=f'{s}_{test_jet}_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert validation file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert testing file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
